100000
200000
300000
400000
500000
600000
700000
800000
900000
1000000
1100000
1200000
1300000
1400000
1500000
1600000
1700000
1800000
1900000
wordVectorsDic length 1917494
number of documents is  30322
self.V=all the words in all documents
12301
SampleNo:1
result/

---------RUN-------- 0
K0iterNum5SampleNum1alpha0.03beta0.03BatchNum16BatchSaved16
No timefil!
before call run_MStream, self.K=0,self.iterNum=5, self.V=12301
batchNum2tweetID is  {1: 1897, 2: 3794, 3: 5691, 4: 7588, 5: 9485, 6: 11382, 7: 13279, 8: 15176, 9: 17073, 10: 18970, 11: 20867, 12: 22764, 13: 24661, 14: 26558, 15: 28455, 16: -1}
Batch 1
30322
	1896 documents will be analyze. alpha is 56.88.
	Initialization.
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
maxPredLabel=458
outlier=31, non-outlier=1865,=maxPredLabel=567
high_entropy_words=497, total words=3790
outsPerCluster.values(), nonOuts 31 1865
[24, 59, 27, 20, 17, 42, 6, 33, 22, 30, 28, 19, 11, 36, 39, 10, 46, 23, 4, 26, 31, 56, 26, 10, 22, 5, 7, 5, 14, 9, 30, 8, 7, 26, 9, 5, 4, 124, 33, 7, 24, 20, 19, 22, 10, 11, 9, 17, 20, 33, 6, 6, 4, 15, 13, 3, 14, 17, 7, 3, 19, 2, 9, 15, 14, 3, 4, 14, 3, 11, 2, 2, 4, 2, 15, 20, 2, 2, 20, 2, 12, 2, 4, 6, 5, 4, 6, 3, 5, 4, 8, 5, 7, 11, 8, 5, 103, 5, 6, 44, 7, 128, 3, 2, 3, 63, 2, 4, 2]
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
	iter is  6
	iter is  7
	iter is  8
	iter is  9
	iter is  10
oldPredLabel not cluster=old439, cluster=749
oldPredLabel not cluster=old447, cluster=757
Evaluate 2
evaluate total texts=1896
homogeneity_score-whole-data:   0.89058642
completeness_score-whole-data:   0.81990248
nmi_score-whole-data:   0.85378398
pred clusters=138, true clusters=89
purity majority whole data=0.8523206751054853
	Gibbs sampling successful! Start to saving results.
start doc=0, end doc=1896
total texts=1896, total clusters=140
	Saving successful!
Batch 2
30322
	3793 documents will be analyze. alpha is 113.79.
	Initialization.
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
maxPredLabel=921
to delete batch 3 2
dict_keys([2, 3])
targetbatchNo 2
len(docsPerBatch) 1896
outlier=40, non-outlier=1857,=maxPredLabel=1020
high_entropy_words=514, total words=3727
outsPerCluster.values(), nonOuts 40 3722
[50, 76, 53, 44, 37, 68, 28, 73, 41, 39, 33, 38, 14, 44, 62, 21, 61, 33, 6, 35, 53, 103, 59, 33, 29, 16, 9, 16, 76, 16, 67, 10, 17, 51, 29, 154, 4, 146, 58, 23, 55, 23, 30, 68, 12, 11, 9, 56, 128, 61, 9, 8, 4, 25, 19, 8, 39, 24, 19, 3, 24, 4, 19, 57, 33, 5, 11, 21, 5, 29, 2, 2, 10, 8, 32, 51, 2, 2, 28, 2, 53, 5, 20, 8, 5, 15, 22, 3, 8, 10, 15, 8, 7, 58, 16, 5, 149, 5, 6, 55, 40, 130, 6, 2, 3, 115, 2, 7, 10, 2, 2, 2, 2, 11, 2, 2, 3, 108, 2, 10, 3, 2]
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
	iter is  6
	iter is  7
	iter is  8
	iter is  9
	iter is  10
Evaluate 3
evaluate total texts=1897
homogeneity_score-whole-data:   0.89780667
completeness_score-whole-data:   0.85194095
nmi_score-whole-data:   0.87427268
pred clusters=137, true clusters=89
purity majority whole data=0.8539799683711122
	Gibbs sampling successful! Start to saving results.
start doc=1896, end doc=3793
total texts=3793, total clusters=171
	Saving successful!
Batch 3
30322
	5690 documents will be analyze. alpha is 170.70.
	Initialization.
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
maxPredLabel=1080
to delete batch 4 3
dict_keys([2, 3, 4])
targetbatchNo 3
len(docsPerBatch) 1897
outlier=44, non-outlier=1853,=maxPredLabel=1171
high_entropy_words=494, total words=3654
outsPerCluster.values(), nonOuts 44 5575
[177, 79, 85, 76, 50, 118, 28, 102, 46, 46, 39, 59, 16, 44, 67, 32, 61, 51, 8, 37, 62, 138, 80, 53, 41, 113, 11, 27, 117, 22, 95, 26, 18, 62, 32, 155, 4, 229, 88, 29, 92, 43, 37, 80, 12, 11, 9, 73, 159, 77, 13, 15, 4, 32, 23, 13, 56, 49, 28, 3, 53, 4, 55, 177, 50, 5, 21, 23, 5, 43, 2, 2, 43, 11, 45, 205, 2, 2, 31, 2, 77, 5, 22, 8, 5, 31, 36, 3, 10, 54, 25, 11, 7, 109, 31, 5, 154, 5, 6, 91, 40, 130, 9, 2, 3, 136, 2, 18, 20, 2, 2, 5, 2, 27, 2, 9, 3, 149, 2, 47, 3, 4, 6, 4, 3, 2, 2, 3, 2, 3, 3, 2]
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
	iter is  6
	iter is  7
	iter is  8
	iter is  9
	iter is  10
Evaluate 4
evaluate total texts=1897
homogeneity_score-whole-data:   0.88317929
completeness_score-whole-data:   0.83746802
nmi_score-whole-data:   0.85971647
pred clusters=135, true clusters=86
purity majority whole data=0.8518713758566157
	Gibbs sampling successful! Start to saving results.
start doc=3793, end doc=5690
total texts=5690, total clusters=198
	Saving successful!
Batch 4
30322
	7587 documents will be analyze. alpha is 227.61.
	Initialization.
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
maxPredLabel=1224
to delete batch 5 4
dict_keys([2, 3, 4, 5])
targetbatchNo 4
len(docsPerBatch) 1897
outlier=36, non-outlier=1861,=maxPredLabel=1303
high_entropy_words=475, total words=3680
outsPerCluster.values(), nonOuts 36 7436
[177, 79, 124, 111, 52, 186, 28, 137, 47, 46, 50, 79, 16, 44, 67, 35, 61, 74, 8, 37, 66, 169, 114, 78, 54, 127, 11, 38, 175, 32, 142, 30, 18, 69, 42, 155, 4, 246, 141, 51, 128, 51, 37, 87, 12, 11, 9, 116, 264, 93, 51, 21, 4, 40, 26, 20, 77, 534, 37, 3, 59, 4, 73, 195, 102, 5, 27, 23, 5, 56, 2, 2, 51, 11, 59, 286, 2, 2, 31, 2, 79, 5, 22, 8, 5, 55, 63, 3, 10, 56, 29, 16, 7, 115, 42, 5, 154, 5, 6, 131, 40, 130, 11, 2, 3, 141, 2, 22, 21, 2, 2, 5, 2, 44, 2, 11, 3, 172, 2, 47, 3, 4, 22, 4, 5, 2, 2, 5, 2, 3, 3, 2, 4, 6, 6, 5, 2, 3, 2, 2, 15, 5, 2, 9]
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
	iter is  6
	iter is  7
	iter is  8
	iter is  9
	iter is  10
Evaluate 5
evaluate total texts=1897
homogeneity_score-whole-data:   0.80517476
completeness_score-whole-data:   0.81981968
nmi_score-whole-data:   0.81243123
pred clusters=111, true clusters=75
purity majority whole data=0.746441750131787
	Gibbs sampling successful! Start to saving results.
start doc=5690, end doc=7587
total texts=7587, total clusters=221
	Saving successful!
Batch 5
30322
	9484 documents will be analyze. alpha is 284.52.
	Initialization.
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
maxPredLabel=1411
to delete batch 6 5
dict_keys([2, 3, 4, 5, 6])
targetbatchNo 5
len(docsPerBatch) 1897
outlier=46, non-outlier=1851,=maxPredLabel=1488
high_entropy_words=387, total words=3191
outsPerCluster.values(), nonOuts 46 9287
[177, 79, 126, 119, 52, 204, 28, 434, 47, 46, 50, 455, 16, 44, 67, 35, 61, 81, 8, 37, 68, 173, 117, 83, 54, 229, 11, 38, 182, 60, 154, 37, 18, 80, 42, 155, 4, 251, 173, 54, 134, 52, 37, 87, 12, 11, 9, 135, 267, 99, 56, 62, 4, 60, 26, 22, 85, 625, 37, 3, 59, 4, 77, 250, 112, 5, 27, 23, 5, 57, 2, 2, 51, 11, 72, 291, 2, 2, 31, 2, 79, 5, 22, 8, 5, 60, 75, 3, 10, 56, 29, 18, 7, 115, 44, 5, 154, 5, 6, 170, 40, 130, 11, 2, 3, 143, 2, 22, 21, 2, 2, 5, 2, 57, 2, 11, 3, 174, 2, 47, 3, 4, 22, 4, 5, 2, 2, 5, 2, 3, 3, 2, 4, 6, 6, 5, 7, 3, 67, 11, 15, 5, 2, 9, 2, 7, 3, 2, 56, 2, 76, 9, 2, 29, 45, 2, 7, 2, 14, 20, 13, 11, 4, 6, 4, 88, 2, 16, 3, 2, 10, 11, 4, 3, 2, 19]
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
	iter is  6
	iter is  7
	iter is  8
	iter is  9
	iter is  10
Evaluate 6
evaluate total texts=1897
homogeneity_score-whole-data:   0.88173017
completeness_score-whole-data:   0.89967302
nmi_score-whole-data:   0.89061123
pred clusters=120, true clusters=108
purity majority whole data=0.8671586715867159
	Gibbs sampling successful! Start to saving results.
start doc=7587, end doc=9484
total texts=9484, total clusters=267
	Saving successful!
Batch 6
30322
	11381 documents will be analyze. alpha is 341.43.
	Initialization.
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
maxPredLabel=1602
to delete batch 7 6
dict_keys([2, 3, 4, 5, 6, 7])
targetbatchNo 6
len(docsPerBatch) 1897
outlier=43, non-outlier=1854,=maxPredLabel=1666
high_entropy_words=355, total words=3248
outsPerCluster.values(), nonOuts 43 11141
[177, 79, 126, 155, 52, 205, 28, 434, 47, 46, 50, 482, 16, 44, 67, 35, 61, 84, 8, 37, 70, 173, 130, 88, 54, 245, 11, 43, 185, 123, 171, 38, 18, 304, 42, 155, 4, 262, 440, 98, 134, 52, 37, 87, 12, 11, 9, 135, 267, 158, 56, 65, 4, 122, 26, 22, 87, 628, 37, 3, 59, 4, 82, 255, 114, 5, 27, 23, 5, 64, 2, 2, 51, 11, 72, 353, 2, 2, 31, 2, 79, 5, 22, 8, 5, 64, 98, 3, 10, 56, 29, 18, 7, 115, 44, 5, 154, 5, 6, 175, 40, 130, 11, 2, 3, 143, 2, 32, 21, 2, 2, 5, 2, 57, 2, 11, 3, 176, 2, 47, 3, 4, 22, 4, 5, 2, 2, 5, 2, 3, 3, 2, 4, 6, 6, 5, 7, 3, 81, 27, 15, 5, 2, 9, 2, 18, 6, 2, 123, 2, 81, 165, 2, 84, 94, 2, 14, 2, 50, 22, 32, 31, 19, 13, 4, 93, 2, 152, 3, 2, 10, 17, 11, 32, 2, 82, 3, 2, 28, 2, 9, 2, 9, 2, 3, 2, 2, 70]
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
	iter is  6
	iter is  7
	iter is  8
	iter is  9
	iter is  10
Evaluate 7
evaluate total texts=1897
homogeneity_score-whole-data:   0.92235440
completeness_score-whole-data:   0.92999491
nmi_score-whole-data:   0.92615890
pred clusters=109, true clusters=82
purity majority whole data=0.9172377438060095
	Gibbs sampling successful! Start to saving results.
start doc=9484, end doc=11381
total texts=11381, total clusters=301
	Saving successful!
Batch 7
30322
	13278 documents will be analyze. alpha is 398.34.
	Initialization.
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
maxPredLabel=1804
to delete batch 8 7
dict_keys([2, 3, 4, 5, 6, 7, 8])
targetbatchNo 7
len(docsPerBatch) 1897
outlier=43, non-outlier=1854,=maxPredLabel=1850
high_entropy_words=297, total words=3055
outsPerCluster.values(), nonOuts 43 12995
[177, 79, 126, 182, 52, 205, 28, 434, 47, 46, 50, 488, 16, 44, 67, 35, 61, 95, 8, 37, 391, 173, 144, 90, 54, 245, 11, 46, 185, 142, 172, 38, 18, 307, 42, 155, 4, 267, 450, 333, 134, 52, 37, 87, 12, 11, 9, 135, 426, 158, 56, 65, 4, 124, 26, 22, 87, 634, 37, 3, 59, 4, 82, 257, 114, 5, 27, 23, 5, 64, 2, 2, 51, 11, 72, 361, 2, 2, 31, 2, 81, 5, 22, 8, 5, 67, 114, 3, 10, 56, 29, 18, 7, 115, 44, 5, 154, 5, 6, 175, 40, 130, 11, 2, 3, 143, 2, 32, 21, 2, 2, 5, 2, 57, 2, 11, 3, 176, 2, 47, 3, 4, 22, 4, 5, 2, 2, 5, 2, 3, 3, 2, 4, 6, 6, 5, 7, 3, 84, 38, 15, 5, 2, 9, 2, 18, 6, 2, 213, 2, 81, 172, 2, 288, 101, 2, 18, 2, 77, 22, 40, 38, 21, 13, 4, 93, 2, 164, 3, 2, 12, 24, 20, 53, 2, 87, 3, 2, 28, 2, 13, 2, 24, 2, 3, 2, 2, 253, 2, 2, 2, 6, 2, 2, 355]
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
	iter is  6
	iter is  7
	iter is  8
	iter is  9
	iter is  10
Evaluate 8
evaluate total texts=1897
homogeneity_score-whole-data:   0.91012276
completeness_score-whole-data:   0.95527581
nmi_score-whole-data:   0.93215281
pred clusters=87, true clusters=73
purity majority whole data=0.893516078017923
	Gibbs sampling successful! Start to saving results.
start doc=11381, end doc=13278
total texts=13278, total clusters=326
	Saving successful!
Batch 8
30322
	15175 documents will be analyze. alpha is 455.25.
	Initialization.
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
maxPredLabel=2157
to delete batch 9 8
dict_keys([2, 3, 4, 5, 6, 7, 8, 9])
targetbatchNo 8
len(docsPerBatch) 1897
outlier=49, non-outlier=1848,=maxPredLabel=2213
high_entropy_words=358, total words=3467
outsPerCluster.values(), nonOuts 49 14843
[177, 79, 126, 239, 52, 205, 28, 434, 47, 46, 50, 488, 16, 44, 67, 35, 61, 101, 8, 37, 391, 173, 186, 142, 54, 245, 11, 48, 185, 183, 172, 38, 18, 310, 42, 155, 4, 293, 459, 344, 134, 52, 37, 87, 12, 11, 9, 135, 440, 158, 56, 65, 4, 255, 26, 22, 87, 635, 37, 3, 59, 4, 87, 267, 114, 5, 27, 23, 5, 64, 2, 2, 51, 11, 72, 370, 2, 2, 31, 2, 81, 5, 22, 8, 5, 73, 140, 3, 10, 56, 29, 18, 7, 115, 44, 5, 154, 5, 6, 177, 40, 130, 11, 2, 3, 143, 2, 32, 21, 2, 2, 5, 2, 57, 2, 11, 3, 176, 2, 47, 3, 4, 22, 4, 5, 2, 2, 5, 2, 3, 3, 2, 4, 6, 6, 5, 7, 3, 207, 68, 15, 5, 2, 9, 2, 18, 6, 2, 307, 2, 81, 179, 2, 378, 115, 2, 59, 2, 135, 22, 63, 84, 27, 18, 4, 93, 2, 203, 3, 2, 12, 46, 24, 123, 2, 87, 3, 2, 28, 2, 13, 2, 48, 2, 5, 2, 7, 320, 2, 2, 2, 8, 2, 44, 726, 3, 22, 3, 4, 2, 3, 3, 7, 2, 34, 58, 3, 55, 6, 3, 2]
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
	iter is  6
	iter is  7
	iter is  8
	iter is  9
	iter is  10
Evaluate 9
evaluate total texts=1897
homogeneity_score-whole-data:   0.85684282
completeness_score-whole-data:   0.91406400
nmi_score-whole-data:   0.88452895
pred clusters=104, true clusters=86
purity majority whole data=0.7949393779652082
	Gibbs sampling successful! Start to saving results.
start doc=13278, end doc=15175
total texts=15175, total clusters=375
	Saving successful!
Batch 9
30322
	17072 documents will be analyze. alpha is 512.16.
	Initialization.
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
maxPredLabel=2441
to delete batch 10 9
dict_keys([2, 3, 4, 5, 6, 7, 8, 9, 10])
targetbatchNo 9
len(docsPerBatch) 1897
outlier=51, non-outlier=1846,=maxPredLabel=2505
high_entropy_words=314, total words=3194
outsPerCluster.values(), nonOuts 51 16689
[177, 79, 126, 269, 52, 205, 28, 434, 47, 46, 50, 488, 16, 44, 67, 35, 61, 109, 8, 37, 391, 173, 304, 178, 54, 245, 11, 66, 185, 237, 172, 38, 18, 310, 42, 155, 4, 693, 489, 344, 134, 52, 37, 87, 12, 11, 9, 135, 447, 158, 56, 65, 4, 255, 26, 22, 87, 635, 37, 3, 59, 4, 94, 278, 114, 5, 27, 23, 5, 68, 2, 2, 51, 11, 72, 384, 2, 2, 31, 2, 81, 5, 22, 8, 5, 82, 181, 3, 10, 56, 29, 18, 7, 115, 44, 5, 154, 5, 6, 177, 40, 130, 11, 2, 3, 143, 2, 32, 21, 2, 2, 5, 2, 57, 2, 11, 3, 176, 2, 47, 3, 4, 22, 4, 5, 2, 2, 5, 2, 3, 3, 2, 4, 6, 6, 5, 7, 3, 233, 98, 15, 5, 2, 9, 2, 18, 6, 2, 383, 2, 81, 186, 2, 465, 117, 2, 118, 2, 200, 22, 84, 114, 44, 20, 4, 93, 2, 376, 3, 2, 12, 53, 26, 148, 2, 93, 3, 2, 28, 2, 13, 2, 75, 2, 27, 2, 7, 325, 2, 2, 2, 8, 2, 79, 764, 3, 29, 3, 4, 4, 3, 3, 7, 2, 47, 63, 3, 102, 6, 3, 2, 2, 2, 7, 2, 3, 2, 2, 4, 2, 3, 40, 2, 5, 19, 4, 2, 61, 39, 2, 4, 4, 2, 2, 2, 2, 4]
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
	iter is  6
	iter is  7
	iter is  8
	iter is  9
	iter is  10
Evaluate 10
evaluate total texts=1897
homogeneity_score-whole-data:   0.87698630
completeness_score-whole-data:   0.91123958
nmi_score-whole-data:   0.89378488
pred clusters=111, true clusters=80
purity majority whole data=0.8255139694254086
	Gibbs sampling successful! Start to saving results.
start doc=15175, end doc=17072
total texts=17072, total clusters=423
	Saving successful!
Batch 10
30322
	18969 documents will be analyze. alpha is 569.07.
	Initialization.
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
maxPredLabel=2630
to delete batch 11 10
dict_keys([2, 3, 4, 5, 6, 7, 8, 9, 10, 11])
targetbatchNo 10
len(docsPerBatch) 1897
outlier=29, non-outlier=1868,=maxPredLabel=2688
high_entropy_words=295, total words=2883
outsPerCluster.values(), nonOuts 29 18557
[177, 79, 126, 315, 52, 205, 28, 434, 47, 46, 50, 488, 16, 44, 67, 35, 61, 120, 8, 37, 391, 173, 342, 211, 54, 245, 11, 108, 185, 256, 172, 38, 18, 310, 42, 155, 4, 708, 489, 344, 134, 52, 37, 87, 12, 11, 9, 135, 481, 158, 56, 65, 4, 255, 26, 22, 87, 635, 37, 3, 59, 4, 111, 280, 114, 5, 27, 23, 5, 68, 2, 2, 51, 11, 72, 389, 2, 2, 31, 2, 81, 5, 22, 8, 5, 82, 202, 3, 10, 56, 29, 18, 7, 115, 44, 5, 154, 5, 6, 177, 40, 130, 11, 2, 3, 143, 2, 32, 21, 2, 2, 5, 2, 57, 2, 11, 3, 176, 2, 47, 3, 4, 22, 4, 5, 2, 2, 5, 2, 3, 3, 2, 4, 6, 6, 5, 7, 3, 233, 118, 15, 5, 2, 9, 2, 18, 6, 2, 462, 2, 81, 189, 2, 467, 139, 2, 143, 2, 230, 22, 94, 137, 58, 20, 4, 93, 2, 519, 3, 2, 12, 79, 26, 162, 2, 93, 3, 2, 28, 2, 13, 2, 150, 2, 31, 2, 7, 327, 2, 2, 2, 8, 2, 95, 769, 3, 29, 3, 4, 10, 3, 3, 35, 2, 49, 63, 3, 142, 6, 3, 2, 2, 2, 15, 2, 3, 2, 2, 14, 23, 9, 58, 2, 20, 19, 8, 2, 71, 39, 2, 10, 12, 2, 2, 4, 2, 232, 2, 2, 3, 2, 3, 501, 3, 3, 127, 3, 5, 4, 2]
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
	iter is  6
	iter is  7
	iter is  8
	iter is  9
	iter is  10
Evaluate 11
evaluate total texts=1897
homogeneity_score-whole-data:   0.92881087
completeness_score-whole-data:   0.95804085
nmi_score-whole-data:   0.94319945
pred clusters=85, true clusters=77
purity majority whole data=0.9130205587770164
	Gibbs sampling successful! Start to saving results.
start doc=17072, end doc=18969
total texts=18969, total clusters=454
	Saving successful!
Batch 11
30322
	20866 documents will be analyze. alpha is 625.98.
	Initialization.
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
maxPredLabel=2925
to delete batch 12 11
dict_keys([2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])
targetbatchNo 11
len(docsPerBatch) 1897
outlier=50, non-outlier=1847,=maxPredLabel=2988
high_entropy_words=288, total words=3118
outsPerCluster.values(), nonOuts 50 20404
[177, 79, 126, 350, 52, 205, 28, 434, 47, 46, 50, 488, 16, 44, 67, 35, 61, 129, 8, 37, 391, 173, 379, 211, 54, 245, 11, 126, 185, 273, 172, 38, 18, 310, 42, 155, 4, 727, 489, 344, 134, 52, 37, 87, 12, 11, 9, 135, 489, 158, 56, 65, 4, 255, 26, 22, 87, 635, 37, 3, 59, 4, 174, 280, 114, 5, 27, 23, 5, 68, 2, 2, 51, 11, 72, 391, 2, 2, 31, 2, 81, 5, 22, 8, 5, 82, 218, 3, 10, 56, 29, 18, 7, 115, 44, 5, 154, 5, 6, 187, 40, 130, 11, 2, 3, 143, 2, 32, 21, 2, 2, 5, 2, 57, 2, 11, 3, 176, 2, 47, 3, 4, 22, 4, 5, 2, 2, 5, 2, 3, 3, 2, 4, 6, 6, 5, 7, 3, 233, 133, 15, 5, 2, 9, 2, 18, 6, 2, 575, 2, 81, 191, 2, 467, 173, 2, 157, 2, 260, 22, 186, 149, 74, 20, 4, 93, 2, 548, 3, 2, 12, 86, 26, 182, 2, 105, 3, 2, 28, 2, 13, 2, 329, 2, 31, 2, 7, 356, 2, 2, 2, 8, 2, 115, 785, 3, 29, 3, 4, 10, 3, 3, 158, 2, 49, 63, 3, 174, 6, 3, 2, 2, 2, 24, 2, 3, 2, 2, 18, 27, 12, 63, 2, 132, 19, 8, 2, 78, 39, 2, 10, 20, 2, 2, 4, 2, 232, 2, 2, 10, 2, 5, 502, 3, 3, 201, 12, 11, 4, 2, 9, 49, 13, 3, 98, 2, 31, 3, 2, 2, 3, 2, 45, 3, 8, 5, 39, 240, 2, 2, 6]
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
	iter is  6
	iter is  7
	iter is  8
	iter is  9
	iter is  10
Evaluate 12
evaluate total texts=1897
homogeneity_score-whole-data:   0.92897383
completeness_score-whole-data:   0.94512877
nmi_score-whole-data:   0.93698167
pred clusters=111, true clusters=79
purity majority whole data=0.8914074855034264
	Gibbs sampling successful! Start to saving results.
start doc=18969, end doc=20866
total texts=20866, total clusters=506
	Saving successful!
Batch 12
30322
	22763 documents will be analyze. alpha is 682.89.
	Initialization.
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
maxPredLabel=3147
to delete batch 13 12
dict_keys([2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])
targetbatchNo 12
len(docsPerBatch) 1897
outlier=33, non-outlier=1864,=maxPredLabel=3211
high_entropy_words=313, total words=3240
outsPerCluster.values(), nonOuts 33 22268
[177, 79, 126, 411, 52, 205, 28, 434, 47, 46, 50, 488, 16, 44, 67, 35, 61, 141, 8, 37, 391, 173, 442, 211, 54, 245, 11, 138, 185, 304, 172, 38, 18, 310, 42, 155, 4, 732, 489, 344, 134, 52, 37, 87, 12, 11, 9, 135, 565, 158, 56, 65, 4, 255, 26, 22, 87, 635, 37, 3, 59, 4, 176, 280, 114, 5, 27, 23, 5, 68, 2, 2, 51, 11, 72, 438, 2, 2, 31, 2, 81, 5, 22, 8, 5, 82, 253, 3, 10, 56, 29, 18, 7, 115, 44, 5, 154, 5, 6, 187, 40, 130, 11, 2, 3, 143, 2, 32, 21, 2, 2, 5, 2, 57, 2, 11, 3, 176, 2, 47, 3, 4, 22, 4, 5, 2, 2, 5, 2, 3, 3, 2, 4, 6, 6, 5, 7, 3, 233, 178, 15, 5, 2, 9, 2, 18, 6, 2, 696, 2, 81, 198, 2, 467, 173, 2, 177, 2, 322, 22, 235, 166, 74, 20, 4, 93, 2, 1012, 3, 2, 12, 123, 26, 223, 2, 112, 3, 2, 28, 2, 13, 2, 355, 2, 31, 2, 7, 383, 2, 2, 2, 8, 2, 200, 789, 3, 29, 3, 4, 13, 3, 3, 158, 2, 49, 63, 3, 207, 6, 3, 2, 2, 2, 34, 2, 3, 2, 2, 18, 36, 46, 74, 2, 220, 19, 8, 2, 78, 39, 5, 10, 20, 2, 2, 4, 2, 232, 2, 2, 21, 2, 25, 504, 3, 3, 206, 21, 19, 4, 2, 9, 52, 16, 3, 103, 6, 45, 3, 4, 2, 3, 2, 49, 3, 20, 12, 59, 240, 2, 2, 6, 10, 2, 4, 3, 2, 2, 12, 2, 4, 3, 3, 4, 3, 13, 121]
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
	iter is  6
	iter is  7
	iter is  8
	iter is  9
	iter is  10
Evaluate 13
evaluate total texts=1897
homogeneity_score-whole-data:   0.94217417
completeness_score-whole-data:   0.94110885
nmi_score-whole-data:   0.94164121
pred clusters=94, true clusters=75
purity majority whole data=0.9309435951502372
	Gibbs sampling successful! Start to saving results.
start doc=20866, end doc=22763
total texts=22763, total clusters=538
	Saving successful!
Batch 13
30322
	24660 documents will be analyze. alpha is 739.80.
	Initialization.
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
maxPredLabel=3606
to delete batch 14 13
dict_keys([2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])
targetbatchNo 13
len(docsPerBatch) 1897
outlier=75, non-outlier=1822,=maxPredLabel=3684
high_entropy_words=331, total words=3273
outsPerCluster.values(), nonOuts 75 24090
[177, 79, 126, 440, 52, 207, 28, 434, 47, 46, 50, 488, 16, 44, 67, 35, 61, 146, 8, 37, 391, 173, 483, 211, 54, 245, 11, 150, 185, 345, 172, 38, 18, 310, 42, 155, 4, 732, 489, 345, 134, 52, 37, 87, 12, 11, 9, 135, 616, 158, 56, 65, 4, 255, 26, 22, 87, 635, 37, 3, 59, 4, 176, 280, 114, 5, 27, 23, 5, 68, 2, 2, 51, 11, 72, 484, 2, 2, 31, 2, 81, 5, 22, 8, 5, 82, 273, 3, 10, 56, 29, 18, 7, 115, 44, 5, 154, 5, 6, 187, 40, 130, 11, 2, 3, 143, 2, 32, 21, 2, 2, 5, 2, 57, 2, 11, 3, 176, 2, 47, 3, 4, 22, 4, 5, 2, 2, 5, 2, 3, 3, 2, 4, 6, 6, 5, 7, 3, 233, 266, 15, 5, 2, 9, 2, 18, 6, 2, 832, 2, 81, 220, 2, 467, 188, 2, 200, 2, 322, 22, 242, 173, 74, 20, 4, 93, 2, 1055, 3, 2, 12, 125, 26, 227, 2, 124, 3, 2, 28, 2, 13, 2, 370, 2, 31, 2, 7, 394, 2, 2, 2, 8, 2, 231, 808, 3, 29, 3, 4, 16, 3, 3, 158, 4, 49, 63, 3, 245, 6, 3, 2, 2, 2, 36, 2, 3, 2, 2, 82, 41, 50, 80, 2, 220, 19, 8, 2, 78, 39, 24, 59, 20, 2, 2, 4, 2, 232, 2, 2, 96, 2, 38, 656, 3, 3, 222, 21, 30, 4, 2, 9, 77, 16, 3, 103, 6, 216, 3, 4, 2, 3, 2, 49, 3, 20, 15, 63, 240, 2, 2, 6, 15, 2, 4, 6, 2, 2, 12, 2, 4, 16, 6, 4, 35, 13, 167, 8, 9, 3, 4, 10, 2, 5, 2, 5, 2, 3, 76, 11, 4, 3, 4, 4, 166, 12, 14, 2, 5, 2, 7, 2, 6, 2, 2]
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
	iter is  6
	iter is  7
	iter is  8
	iter is  9
	iter is  10
Evaluate 14
evaluate total texts=1897
homogeneity_score-whole-data:   0.90173574
completeness_score-whole-data:   0.89808253
nmi_score-whole-data:   0.89990543
pred clusters=149, true clusters=96
purity majority whole data=0.8755930416447022
	Gibbs sampling successful! Start to saving results.
start doc=22763, end doc=24660
total texts=24660, total clusters=622
	Saving successful!
Batch 14
30322
	26557 documents will be analyze. alpha is 796.71.
	Initialization.
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
maxPredLabel=4014
to delete batch 15 14
dict_keys([2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])
targetbatchNo 14
len(docsPerBatch) 1897
outlier=69, non-outlier=1828,=maxPredLabel=4078
high_entropy_words=342, total words=3332
outsPerCluster.values(), nonOuts 69 25918
[177, 79, 126, 451, 52, 207, 28, 434, 47, 46, 50, 488, 16, 44, 67, 35, 61, 146, 8, 37, 391, 173, 503, 211, 54, 245, 11, 150, 185, 378, 172, 38, 18, 310, 42, 155, 4, 732, 489, 345, 134, 52, 37, 87, 12, 11, 9, 135, 631, 158, 56, 65, 4, 255, 26, 22, 87, 635, 37, 3, 59, 4, 176, 280, 114, 5, 27, 23, 5, 68, 2, 2, 51, 11, 72, 484, 2, 2, 31, 2, 81, 5, 22, 8, 5, 82, 310, 3, 10, 56, 29, 18, 7, 115, 44, 5, 154, 5, 6, 187, 40, 130, 11, 2, 3, 143, 2, 32, 21, 2, 2, 5, 2, 57, 2, 11, 3, 176, 2, 47, 3, 4, 22, 4, 5, 2, 2, 5, 2, 3, 3, 2, 4, 6, 6, 5, 7, 3, 233, 266, 15, 5, 2, 9, 2, 18, 6, 2, 911, 2, 81, 220, 2, 467, 215, 2, 200, 2, 322, 22, 243, 176, 74, 20, 4, 93, 2, 1055, 3, 2, 12, 125, 26, 227, 2, 124, 3, 2, 28, 2, 13, 2, 370, 2, 31, 2, 7, 463, 2, 2, 2, 8, 2, 243, 821, 3, 29, 3, 4, 16, 3, 3, 158, 11, 49, 63, 3, 245, 6, 3, 2, 2, 2, 36, 2, 3, 2, 2, 118, 48, 50, 86, 2, 220, 19, 8, 2, 78, 39, 27, 183, 20, 2, 2, 4, 2, 232, 2, 2, 196, 2, 94, 1090, 3, 3, 246, 21, 30, 4, 2, 9, 77, 16, 3, 103, 6, 216, 3, 4, 2, 3, 2, 49, 3, 20, 15, 63, 240, 2, 2, 6, 25, 2, 4, 6, 2, 2, 12, 2, 4, 16, 6, 4, 35, 13, 177, 8, 9, 3, 4, 13, 2, 36, 2, 5, 2, 3, 214, 17, 4, 15, 7, 6, 249, 51, 85, 2, 18, 9, 62, 16, 8, 2, 36, 3, 4, 26, 58, 3, 4, 6, 3, 14, 2, 2, 2, 4, 13, 4, 5, 3, 2, 3, 3, 4, 5, 2, 3]
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
	iter is  6
	iter is  7
	iter is  8
	iter is  9
	iter is  10
Evaluate 15
evaluate total texts=1897
homogeneity_score-whole-data:   0.92203376
completeness_score-whole-data:   0.79502919
nmi_score-whole-data:   0.85383445
pred clusters=128, true clusters=44
purity majority whole data=0.9256721138639958
	Gibbs sampling successful! Start to saving results.
start doc=24660, end doc=26557
total texts=26557, total clusters=693
	Saving successful!
Batch 15
30322
	28454 documents will be analyze. alpha is 853.62.
	Initialization.
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
maxPredLabel=4280
to delete batch 16 15
dict_keys([2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16])
targetbatchNo 15
len(docsPerBatch) 1897
outlier=47, non-outlier=1850,=maxPredLabel=4333
high_entropy_words=302, total words=2881
outsPerCluster.values(), nonOuts 47 27768
[177, 79, 126, 469, 52, 209, 28, 434, 47, 46, 50, 488, 16, 44, 67, 35, 61, 146, 8, 37, 391, 173, 527, 211, 54, 245, 11, 150, 185, 406, 172, 38, 18, 310, 42, 155, 4, 732, 489, 345, 134, 52, 37, 87, 12, 11, 9, 135, 641, 158, 56, 65, 4, 255, 26, 22, 87, 635, 37, 3, 59, 4, 176, 280, 114, 5, 27, 23, 5, 68, 2, 2, 51, 11, 72, 484, 2, 2, 31, 2, 81, 5, 22, 8, 5, 82, 325, 3, 10, 56, 29, 18, 7, 115, 44, 5, 154, 5, 6, 187, 40, 130, 11, 2, 3, 143, 2, 32, 21, 2, 2, 5, 2, 57, 2, 11, 3, 176, 2, 47, 3, 4, 22, 4, 5, 2, 2, 5, 2, 3, 3, 2, 4, 6, 6, 5, 7, 3, 233, 266, 15, 5, 2, 9, 2, 18, 6, 2, 1320, 2, 81, 220, 2, 467, 226, 2, 200, 2, 322, 22, 243, 176, 74, 20, 4, 93, 2, 1055, 3, 2, 12, 125, 26, 227, 2, 124, 3, 2, 28, 2, 13, 2, 370, 2, 31, 2, 7, 500, 2, 2, 2, 8, 2, 248, 835, 3, 29, 3, 4, 16, 3, 3, 158, 11, 49, 63, 3, 245, 6, 3, 2, 2, 2, 36, 2, 3, 2, 2, 155, 50, 50, 89, 2, 220, 19, 8, 2, 78, 39, 27, 308, 27, 2, 2, 4, 2, 232, 2, 2, 243, 2, 161, 1395, 3, 3, 282, 21, 30, 4, 2, 9, 77, 16, 3, 103, 6, 216, 3, 4, 2, 3, 2, 49, 3, 20, 15, 63, 240, 2, 2, 6, 33, 2, 4, 6, 2, 2, 12, 2, 4, 16, 6, 4, 35, 13, 226, 8, 9, 3, 4, 111, 2, 87, 2, 5, 2, 3, 307, 28, 4, 18, 14, 8, 318, 91, 111, 2, 27, 11, 88, 60, 10, 2, 54, 3, 4, 56, 65, 3, 4, 14, 5, 17, 2, 2, 2, 4, 17, 4, 5, 6, 2, 3, 3, 10, 13, 2, 3, 2, 3, 2, 2, 2, 2, 4, 2]
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
	iter is  6
	iter is  7
	iter is  8
	iter is  9
	iter is  10
Evaluate 16
evaluate total texts=1897
homogeneity_score-whole-data:   0.94557632
completeness_score-whole-data:   0.82832471
nmi_score-whole-data:   0.88307546
pred clusters=99, true clusters=43
purity majority whole data=0.9546652609383237
	Gibbs sampling successful! Start to saving results.
start doc=26557, end doc=28454
total texts=28454, total clusters=727
	Saving successful!
Batch 16
30322
	30322 documents will be analyze. alpha is 909.66.
	Initialization.
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
maxPredLabel=4546
to delete batch 17 16
dict_keys([2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17])
targetbatchNo 16
len(docsPerBatch) 1897
outlier=50, non-outlier=1818,=maxPredLabel=4594
high_entropy_words=366, total words=2120
outsPerCluster.values(), nonOuts 50 29586
[177, 79, 126, 487, 52, 209, 28, 434, 47, 46, 50, 488, 16, 44, 67, 35, 61, 146, 8, 37, 391, 173, 531, 211, 54, 245, 11, 150, 185, 409, 172, 38, 18, 310, 42, 155, 4, 732, 489, 345, 134, 52, 37, 87, 12, 11, 9, 135, 661, 158, 56, 65, 4, 255, 26, 22, 87, 635, 37, 3, 59, 4, 176, 280, 114, 5, 27, 23, 5, 68, 2, 2, 51, 11, 72, 484, 2, 2, 31, 2, 81, 5, 22, 8, 5, 82, 340, 3, 10, 56, 29, 18, 7, 115, 44, 5, 154, 5, 6, 187, 40, 130, 11, 2, 3, 143, 2, 32, 21, 2, 2, 5, 2, 57, 2, 11, 3, 176, 2, 47, 3, 4, 22, 4, 5, 2, 2, 5, 2, 3, 3, 2, 4, 6, 6, 5, 7, 3, 233, 266, 15, 5, 2, 9, 2, 18, 6, 2, 1418, 2, 81, 220, 2, 467, 238, 2, 200, 2, 322, 22, 243, 176, 74, 20, 4, 93, 2, 1055, 3, 2, 12, 125, 26, 227, 2, 124, 3, 2, 28, 2, 13, 2, 370, 2, 31, 2, 7, 507, 2, 2, 2, 8, 2, 248, 842, 3, 29, 3, 4, 16, 3, 3, 158, 11, 49, 63, 3, 245, 6, 3, 2, 2, 2, 36, 2, 3, 2, 2, 158, 50, 50, 95, 2, 220, 19, 8, 2, 78, 39, 27, 314, 29, 2, 2, 4, 2, 232, 2, 2, 288, 2, 196, 1595, 3, 3, 312, 21, 30, 4, 2, 9, 77, 16, 3, 103, 6, 216, 3, 4, 2, 3, 2, 49, 3, 20, 15, 63, 240, 2, 2, 6, 36, 2, 4, 6, 2, 2, 12, 2, 4, 16, 6, 4, 35, 13, 254, 8, 9, 3, 4, 150, 2, 87, 2, 5, 2, 3, 349, 30, 4, 22, 29, 8, 351, 114, 137, 2, 42, 17, 100, 90, 10, 2, 756, 3, 4, 68, 65, 3, 4, 17, 5, 20, 2, 2, 2, 4, 17, 4, 5, 8, 2, 3, 3, 12, 18, 2, 3, 2, 3, 2, 2, 2, 2, 4, 2, 3, 2, 2, 3, 35, 249, 2, 4]
	iter is  1
	iter is  2
	iter is  3
	iter is  4
	iter is  5
	iter is  6
	iter is  7
	iter is  8
	iter is  9
	iter is  10
Evaluate 17
evaluate total texts=1868
homogeneity_score-whole-data:   0.97005316
completeness_score-whole-data:   0.69401048
nmi_score-whole-data:   0.80913619
pred clusters=92, true clusters=42
purity majority whole data=0.9791220556745182
	Gibbs sampling successful! Start to saving results.
start doc=28454, end doc=30322
total texts=30322, total clusters=765
	Saving successful!
time diff secs= 809
pred_true_text_file name=result/mstr-enh
evaluate total texts=30321
homogeneity_score-whole-data:   0.83430084
completeness_score-whole-data:   0.86393681
nmi_score-whole-data:   0.84886024
pred clusters=921, true clusters=269
purity majority whole data=0.7081890438969691
pred_true_text_file name=result/NewsPredTueTextMStream_WordArr.txt
evaluate total texts=30322
homogeneity_score-whole-data:   0.83072540
completeness_score-whole-data:   0.86603051
nmi_score-whole-data:   0.84801065
pred clusters=747, true clusters=269
purity majority whole data=0.7050326495613746
